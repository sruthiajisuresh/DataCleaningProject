{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ef48f8-36f3-45d8-9c0b-03c5f310aa93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e9455c3-9618-4c2c-b295-275158e95c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                    ID                     Name  \\\n",
      "0           0  1e407ff9-6255-489d-a0de-34135d4f74bd            Hunter Thomas   \n",
      "1           1  379f55b8-87d5-4739-a146-7400b78c24d1             Jeremy Irwin   \n",
      "2           2  18261368-dfa1-47f0-afc6-bddf45926b07  Jennifer Hammondquickly   \n",
      "3           3  ae7cf7cf-17cf-4c8b-9c44-4f61a9a238e5          Sydney Taylorso   \n",
      "4           4  14ed3e6a-e0f5-4bbe-8d93-8665267f5c90                Julia Lee   \n",
      "\n",
      "    Age                    Email   Join Date    Salary   Department  \n",
      "0  25.0       xlopez@hotmail.com         NaN   88552.0        Sales  \n",
      "1  90.0          Jillian Jenkins  2022-07-07  139227.0          NaN  \n",
      "2  66.0          jscottgreen.biz  2023-11-21   65550.0  Engineering  \n",
      "3  39.0       luke56gonzalez.com  2021-11-05  139932.0     SupportJ  \n",
      "4  71.0  figueroakayla@yahoo.com         NaN  143456.0    Marketing  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11000 entries, 0 to 10999\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  11000 non-null  int64  \n",
      " 1   ID          11000 non-null  object \n",
      " 2   Name        8667 non-null   object \n",
      " 3   Age         9253 non-null   float64\n",
      " 4   Email       9731 non-null   object \n",
      " 5   Join Date   8808 non-null   object \n",
      " 6   Salary      8761 non-null   float64\n",
      " 7   Department  8745 non-null   object \n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 687.6+ KB\n",
      "None\n",
      "Empty DataFrame\n",
      "Columns: [Index, ID, Name, Age, Email, Join Date, Salary, Department]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Load the data from a CSV file\n",
    "\n",
    "#file_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "df = pd.read_csv( 'messy_data.csv')\n",
    "\n",
    "# Inspect the data\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "\n",
    "# Rename the unnamed column to 'index'\n",
    "df.rename(columns={df.columns[0]: 'Index'}, inplace=True)\n",
    "df.to_csv('cleaned_dataset.csv', index=False)\n",
    "# Handle missing values\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['Salary'] = df['Salary'].fillna(df['Salary'].mean())\n",
    "df.dropna(subset=['Name', 'Email'], inplace=True)\n",
    "\n",
    "# Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "# Remove duplicate rows based on 'ID', keeping the first occurrence\n",
    "df = df.drop_duplicates(subset='ID', keep='first')\n",
    "\n",
    "# Correct email formats\n",
    "def is_valid_email(email):\n",
    "    return re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$', email)\n",
    "\n",
    "def is_professional_email(email):\n",
    "    return not any(domain in email for domain in ['hotmail', 'yahoo', 'gmail'])\n",
    "\n",
    "df['Email'] = df['Email'].apply(lambda x: x if is_valid_email(x) else None)\n",
    "df.dropna(subset=['Email'], inplace=True)\n",
    "df = df[df['Email'].apply(is_professional_email)]\n",
    "\n",
    "# Clean name fields\n",
    "def clean_name(name):\n",
    "    return re.sub(r'\\b(Mr\\.|Mrs\\.|Ms\\.|Dr\\.|DDS|DVM)\\b', '', name).strip()\n",
    "\n",
    "df['Name'] = df['Name'].apply(clean_name)\n",
    "\n",
    "# Standardize date formats\n",
    "\n",
    "def parse_date(date_str):\n",
    "    for fmt in ('%Y-%m-%d', '%d/%m/%Y', '%m/%d/%Y'):\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt).strftime('%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return '1970-01-01'  # Default value if unable to parse\n",
    "\n",
    "# Apply the parse_date function to 'Join Date' column\n",
    "df['Join Date'] = df['Join Date'].apply(lambda x: parse_date(x) if pd.notnull(x) else '1970-01-01')\n",
    "\n",
    "# Print the DataFrame to check for empty cells in 'Join Date' column\n",
    "print(df[df['Join Date'].isnull()])\n",
    "\n",
    "# Save the DataFrame back to a CSV file (optional)\n",
    "df.to_csv('cleaned_dataset.csv', index=False)\n",
    "\n",
    "# Correct department names\n",
    "department_mapping = {\n",
    "    'hr': 'HR',\n",
    "    'human resources': 'HR',\n",
    "    'eng': 'Engineering',\n",
    "    'engineering': 'Engineering',\n",
    "    'mktg': 'Marketing',\n",
    "    'marketing': 'Marketing',\n",
    "    'sales': 'Sales',\n",
    "    'support': 'Support',\n",
    "    # Add other variations as necessary\n",
    "}\n",
    "\n",
    "def clean_and_map_department(dept):\n",
    "    if isinstance(dept, str):\n",
    "        dept = dept.lower()\n",
    "        dept = re.sub(r'[^a-z\\s]', '', dept)\n",
    "        corrections = {\n",
    "            'hr': r'h\\s*r|human\\s*resources|h\\s*r',\n",
    "            'engineering': r'eng(?:ineering)?|engineeringi+',\n",
    "            'marketing': r'mktg|marketings?|marketingu+',\n",
    "            'sales': r'salesx?',\n",
    "            'support': r'supporte?'\n",
    "        }\n",
    "\n",
    "        for correct, pattern in corrections.items():\n",
    "            if re.search(pattern, dept):\n",
    "                return correct.capitalize()\n",
    "\n",
    "        return department_mapping.get(dept, dept.capitalize())\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "df['Department'] = df['Department'].apply(clean_and_map_department)\n",
    "\n",
    "# Handle salary noise\n",
    "min_salary = 30000\n",
    "max_salary = 200000\n",
    "df['Salary'] = pd.to_numeric(df['Salary'], errors='coerce')\n",
    "df.loc[(df['Salary'] < min_salary) | (df['Salary'] > max_salary), 'Salary'] = None\n",
    "df['Salary'] = df['Salary'].fillna(df['Salary'].mean())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sort the DataFrame by 'Name' column in ascending order\n",
    "df_sorted = df.sort_values(by='Name')\n",
    "df_sorted.to_csv('cleaned_dataset.csv', index=False, float_format='%.0f')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('cleaned_dataset.csv')\n",
    "\n",
    "# Drop the 'Index' column if it exists\n",
    "if 'Index' in df.columns:\n",
    "    df.drop(columns=['Index'], inplace=True)\n",
    "\n",
    "# Reset the index and drop the old index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Set the index to start from 1\n",
    "df.index = df.index + 1\n",
    "\n",
    "# Save the DataFrame back to a CSV file (optional)\n",
    "df.to_csv('cleaned_dataset.csv', index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac254a-fc7c-4b53-8c6e-0ab7947089b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
